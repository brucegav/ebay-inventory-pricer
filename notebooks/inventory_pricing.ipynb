{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844e3e1-26f0-4de3-9f58-8e30c0608799",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ebaysdk\n",
    "import gspread\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712090f0-5f6c-42fb-a5f5-e7e6cf7cb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to google sheets and test connection\n",
    "\n",
    "load_dotenv()\n",
    "creds_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "gc = gspread.service_account(filename=creds_path)\n",
    "\n",
    "spreadsheet_id = os.getenv(\"SPREADSHEET_ID\")\n",
    "sh = gc.open_by_key(spreadsheet_id)\n",
    "\n",
    "worksheet_list = sh.worksheets()\n",
    "print(f\"Connection successful. Found {len(worksheet_list)} sheets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b166fd-f000-4c35-899c-721293df2027",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_query(row):\n",
    "    # 1. Essential Card Data\n",
    "    year = str(row.get('display_year', row.get('year', '')))\n",
    "    \n",
    "    \n",
    "    components = [\n",
    "        year,\n",
    "        str(row.get('manufacturer', '')),\n",
    "        \n",
    "        str(row.get('product_name', '')), \n",
    "        str(row.get('player_fname', '')),\n",
    "        str(row.get('player_lname', '')),\n",
    "        str(row.get('card_number', '')), # Your existing card number\n",
    "        str(row.get('parallel_color', '')),\n",
    "        str(row.get('variation_name', ''))\n",
    "    ]\n",
    "\n",
    "    \n",
    "    if str(row.get('rookie', '')).upper() == 'TRUE':\n",
    "        components.append(\"RC\")\n",
    "    if str(row.get('autograph', '')).upper() == 'TRUE':\n",
    "        components.append(\"AUTO\")\n",
    "\n",
    "    \n",
    "    final_parts = []\n",
    "    for c in components:\n",
    "        val = str(c).strip()\n",
    "        if val and val.upper() not in [\"FALSE\", \"NONE\"] and val not in final_parts:\n",
    "            final_parts.append(val)\n",
    "            \n",
    "    return \" \".join(final_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6f26e-4e16-45f4-87f5-4675d6ab03de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initialize csv file for search failures\n",
    "\n",
    "with open('failed_searches.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Sheet Name\", \"Row Index\", \"Query\", \"Error Type\"])\n",
    "\n",
    "# 1. Configuration\n",
    "load_dotenv()\n",
    "EBAY_TOKEN = os.getenv(\"EBAY_TOKEN\")\n",
    "SPREADSHEET_ID = os.getenv(\"SPREADSHEET_ID\")\n",
    "target_col_name = \"average_price\"\n",
    "\n",
    "\n",
    "def get_ebay_avg(query, sheet_name, row_idx):\n",
    "    url = \"https://api.ebay.com/buy/browse/v1/item_summary/search\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {EBAY_TOKEN}\",\n",
    "        \"X-EBAY-C-MARKETPLACE-ID\": \"EBAY_US\"\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": query + \" -psa -bgs -sgc -cgc -graded -slab -pca\",\n",
    "        \"filter\": \"buyingOptions:{FIXED_PRICE|AUCTION},lastSoldDate:[2025-12-01T00:00:00Z..2026-01-31T00:00:00Z],conditionIds:{4000}\",\n",
    "        \"limit\": 100\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            items = response.json().get('itemSummaries', [])\n",
    "            \n",
    "            \n",
    "            if not items:\n",
    "                log_failure(sheet_name, row_idx, query, \"No Results Found\")\n",
    "                return 0\n",
    "                \n",
    "            prices = [float(i['price']['value']) for i in items]\n",
    "            if len(prices) > 0:\n",
    "                if len(prices) < 5:\n",
    "                    return round(np.median(prices), 2)\n",
    "                else:\n",
    "                    z_scores = np.abs(stats.zscore(prices))\n",
    "                    filtered = np.array(prices)[z_scores < 2]\n",
    "                    return round(np.mean(filtered), 2)\n",
    "            return 0\n",
    "        else:\n",
    "           \n",
    "            log_failure(sheet_name, row_idx, query, f\"API Error {response.status_code}\")\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        \n",
    "        log_failure(sheet_name, row_idx, query, str(e))\n",
    "        return 0\n",
    "\n",
    "def log_failure(sheet_name, row_idx, query, error_msg):\n",
    "    with open('failed_searches.csv', mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([sheet_name, row_idx, query, error_msg])\n",
    "\n",
    "# 2. Main Processing Loop\n",
    "spreadsheet = gc.open_by_key(SPREADSHEET_ID)\n",
    "all_sheets = spreadsheet.worksheets()\n",
    "\n",
    "for ws in all_sheets:\n",
    "    print(f\"\\n--- Processing Sheet: {ws.title} ---\")\n",
    "    data = ws.get_all_records()\n",
    "    if not data:\n",
    "        print(f\"Skipping {ws.title}: No data found.\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "   \n",
    "    if target_col_name not in df.columns:\n",
    "        print(f\"Adding '{target_col_name}' column to {ws.title}...\")\n",
    "        new_col_idx = len(df.columns) + 1\n",
    "        ws.update_cell(1, new_col_idx, target_col_name)\n",
    "        df[target_col_name] = 0\n",
    "        col_idx = new_col_idx\n",
    "    else:\n",
    "        col_idx = df.columns.get_loc(target_col_name) + 1\n",
    "\n",
    "    # 3. Update Prices \n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        query = build_query(row) \n",
    "        \n",
    "        \n",
    "        avg_price = get_ebay_avg(query, ws.title, index + 2)\n",
    "        \n",
    "        # Write back to Google Sheet\n",
    "        ws.update_cell(index + 2, col_idx, avg_price)\n",
    "        print(f\"Updated {ws.title} Row {index + 2}: {query} -> ${avg_price}\")\n",
    "        \n",
    "        \n",
    "        time.sleep(1.5)\n",
    "\n",
    "print(\"\\nAll 13 sheets processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2d015-a155-4cd2-8d41-1277156e40cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
